{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as jrng\n",
    "from jax import numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_string():\n",
    "    return ''.join([random.choice(string.ascii_letters + string.digits) for n in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def split_and_sample(key, shape):\n",
    "    key, subkey = jrng.split(key)\n",
    "    val = jrng.normal(subkey, shape=shape)\n",
    "    return key, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, name=None):\n",
    "        if name is None:\n",
    "            self.name = F'Layer+{rand_string()}'\n",
    "        else:\n",
    "            self.name = name\n",
    "    \n",
    "    def __call__(self, p, x):\n",
    "        return self.forward(p, x)\n",
    "        \n",
    "    def params(self):\n",
    "        return None\n",
    "    \n",
    "    def init_params(self, rng):\n",
    "        return rng, self.params()\n",
    "    \n",
    "    def forward(self, p, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, d_in, d_out, name=None):\n",
    "        super(Linear, self).__init__(name)\n",
    "        \n",
    "        self.weight = jnp.zeros((d_in, d_out))\n",
    "        self.bias = jnp.zeros((d_out))\n",
    "        \n",
    "        if name is None:\n",
    "            self.name = F'Linear+{rand_string()}'\n",
    "        \n",
    "    def params(self):\n",
    "        return dict([('weight', self.weight), ('bias', self.bias)])\n",
    "    \n",
    "    def init_params(self, rng):\n",
    "        rng, self.weight = split_and_sample(rng, self.weight.shape)\n",
    "        return rng, self.params()\n",
    "    \n",
    "    def forward(self, p, x):\n",
    "        return jnp.dot(x, p['weight']) + p['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(Tanh, self).__init__(name)\n",
    "        \n",
    "        if name is None:\n",
    "            self.name = F'Tanh+{rand_string()}'\n",
    "            \n",
    "    def forward(self, p, x):\n",
    "        return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(Softmax, self).__init__(name)\n",
    "        \n",
    "        if name is None:\n",
    "            self.name = F'Softmax+{rand_string()}'\n",
    "            \n",
    "    def forward(self, p, x):\n",
    "        x_exp = jnp.exp(x)\n",
    "        return x_exp / jnp.sum(x_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, rng, layers, loss=None, name=None):        \n",
    "        if name is None:\n",
    "            name = F'Model+{rand_string()}'\n",
    "            \n",
    "        self.layers = layers\n",
    "        \n",
    "        if type(loss) is not list:\n",
    "            self.loss = [(loss, 1.)]\n",
    "        else:\n",
    "            self.loss = loss\n",
    "            \n",
    "        self.params = dict()\n",
    "        for ll in self.layers:\n",
    "            rng, pp = ll.init_params(rng)\n",
    "            if pp is not None:\n",
    "                self.params[ll.name] = pp\n",
    "        self.params_values, self.params_tree = jax.tree_flatten(self.params)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def forward_(self, p, x):\n",
    "        h = x\n",
    "        for ll in self.layers:\n",
    "            h = ll(None if ll.name not in p else p[ll.name], h)\n",
    "        return h    \n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def loss_(self, p, x, y):\n",
    "        def dummy(mymodel, params, x, y):\n",
    "            total_l = 0.\n",
    "            for ll in mymodel.loss:\n",
    "                total_l = total_l + ll[1] * ll[0](x, y)\n",
    "            return total_l\n",
    "        return jax.vmap(dummy, in_axes=(None,None,0,0))(self, self.params, self.forward_(p, x), y).mean()\n",
    "    \n",
    "    def forward(self, x, single=False):\n",
    "        if single:\n",
    "            return self.forward_(self.params, x)\n",
    "        \n",
    "        def dummy(mymodel, params, x):\n",
    "            return mymodel.forward_(params, x)\n",
    "        return jax.vmap(dummy, in_axes=(None, None, 0))(self, self.params, x)\n",
    "    \n",
    "    def loss_grad(self, x, y):\n",
    "        return self.loss_(self.params, x, y), jax.grad(self.loss_)(self.params, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, model, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "        \n",
    "    def step(self, grad):\n",
    "        for ll in self.model.layers:\n",
    "            if ll.name not in self.model.params:\n",
    "                continue\n",
    "            pp = self.model.params[ll.name]\n",
    "            gg = grad[ll.name]\n",
    "            for kk in pp.keys():\n",
    "                pp[kk] = pp[kk] - self.lr * gg[kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def cross_entropy(p, y):\n",
    "    return -jnp.take(jnp.log(p), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jrng.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model(rng, [Linear(10,10), Tanh(), Linear(10,10), Softmax()], loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = SGD(mymodel, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.328461\n",
      "5.5920944\n",
      "5.567603\n",
      "5.559447\n",
      "5.5554733\n",
      "5.5531588\n",
      "5.5516586\n",
      "5.5506134\n",
      "5.5498476\n",
      "5.549266\n"
     ]
    }
   ],
   "source": [
    "target_labels = numpy.floor(numpy.random.rand(256)).astype('int')\n",
    "inputs = numpy.random.rand(256,10)\n",
    "\n",
    "for ii in range(1000):\n",
    "    loss, grad = mymodel.loss_grad(inputs, target_labels)\n",
    "    \n",
    "    if numpy.mod(ii, 100) == 0:\n",
    "        print(loss)\n",
    "    optim.step(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
