{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as jrng\n",
    "from jax import numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Linear, Conv2d, SpatialPool2d, ReLU, Softmax\n",
    "from model import Model\n",
    "from optimizers import SGD, Adam\n",
    "from functionals import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jrng.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model(rng, [Conv2d(3,3,1,128), ReLU(), \n",
    "                      Conv2d(3,3,128,128), ReLU(), \n",
    "                      SpatialPool2d(), Linear(128,10), \n",
    "                      Softmax()], loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(mymodel, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTDataModule('./mnist/')\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.train_dataloader(batch_size=256)\n",
    "val_loader = data.val_dataloader(batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 8.000088691711426 val acc 0.16455078125\n",
      "epoch 2 loss 7.625463485717773 val acc 0.296875\n",
      "epoch 3 loss 7.418938636779785 val acc 0.4072265625\n",
      "epoch 4 loss 7.274871349334717 val acc 0.499755859375\n",
      "epoch 5 loss 7.145114421844482 val acc 0.568603515625\n",
      "epoch 6 loss 7.0391130447387695 val acc 0.618896484375\n",
      "epoch 7 loss 6.958877086639404 val acc 0.65673828125\n",
      "epoch 8 loss 6.875216484069824 val acc 0.683349609375\n",
      "epoch 9 loss 6.80990743637085 val acc 0.7080078125\n",
      "epoch 10 loss 6.751032829284668 val acc 0.728271484375\n",
      "epoch 11 loss 6.700778007507324 val acc 0.747314453125\n",
      "epoch 12 loss 6.663313865661621 val acc 0.760009765625\n",
      "epoch 13 loss 6.621245861053467 val acc 0.77294921875\n",
      "epoch 14 loss 6.5793867111206055 val acc 0.78369140625\n",
      "epoch 15 loss 6.552623748779297 val acc 0.79736328125\n",
      "epoch 16 loss 6.528267860412598 val acc 0.806396484375\n",
      "epoch 17 loss 6.504374980926514 val acc 0.820068359375\n",
      "epoch 18 loss 6.468982696533203 val acc 0.82373046875\n",
      "epoch 19 loss 6.460025787353516 val acc 0.82763671875\n",
      "epoch 20 loss 6.441269874572754 val acc 0.83056640625\n",
      "epoch 21 loss 6.412555694580078 val acc 0.83740234375\n",
      "epoch 22 loss 6.404048442840576 val acc 0.846923828125\n",
      "epoch 23 loss 6.379194736480713 val acc 0.848388671875\n",
      "epoch 24 loss 6.366629600524902 val acc 0.852294921875\n",
      "epoch 25 loss 6.362867832183838 val acc 0.85400390625\n",
      "epoch 26 loss 6.347858905792236 val acc 0.859375\n",
      "epoch 27 loss 6.331109523773193 val acc 0.86767578125\n",
      "epoch 28 loss 6.3170485496521 val acc 0.8701171875\n",
      "epoch 29 loss 6.315496921539307 val acc 0.8759765625\n",
      "epoch 30 loss 6.297245025634766 val acc 0.8779296875\n",
      "epoch 31 loss 6.296154499053955 val acc 0.880859375\n",
      "epoch 32 loss 6.272058963775635 val acc 0.880615234375\n",
      "epoch 33 loss 6.284062385559082 val acc 0.885009765625\n",
      "epoch 34 loss 6.267919063568115 val acc 0.885009765625\n",
      "epoch 35 loss 6.2538299560546875 val acc 0.88720703125\n",
      "epoch 36 loss 6.2470903396606445 val acc 0.888916015625\n",
      "epoch 37 loss 6.234065055847168 val acc 0.88916015625\n",
      "epoch 38 loss 6.245135307312012 val acc 0.891357421875\n",
      "epoch 39 loss 6.233394622802734 val acc 0.896728515625\n",
      "epoch 40 loss 6.23166036605835 val acc 0.89453125\n",
      "epoch 41 loss 6.219436168670654 val acc 0.900146484375\n",
      "epoch 42 loss 6.213327407836914 val acc 0.900634765625\n",
      "epoch 43 loss 6.211919784545898 val acc 0.901123046875\n",
      "epoch 44 loss 6.200859069824219 val acc 0.9033203125\n",
      "epoch 45 loss 6.197481155395508 val acc 0.905029296875\n",
      "epoch 46 loss 6.201547145843506 val acc 0.90673828125\n",
      "epoch 47 loss 6.194304943084717 val acc 0.909912109375\n",
      "epoch 48 loss 6.189648151397705 val acc 0.911376953125\n",
      "epoch 49 loss 6.185522079467773 val acc 0.91064453125\n",
      "epoch 50 loss 6.181524276733398 val acc 0.91162109375\n",
      "epoch 51 loss 6.183072566986084 val acc 0.91259765625\n",
      "epoch 52 loss 6.164576530456543 val acc 0.912109375\n",
      "epoch 53 loss 6.167078018188477 val acc 0.91455078125\n",
      "epoch 54 loss 6.156547546386719 val acc 0.914794921875\n",
      "epoch 55 loss 6.150198936462402 val acc 0.915771484375\n",
      "epoch 56 loss 6.159797191619873 val acc 0.916748046875\n",
      "epoch 57 loss 6.1559834480285645 val acc 0.91650390625\n",
      "epoch 58 loss 6.154018878936768 val acc 0.91796875\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "loss_running = numpy.Inf\n",
    "\n",
    "for ei in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        x_, y_ = x.data.numpy(), y.data.numpy()\n",
    "        loss, grad = mymodel.loss_grad(x_, y_)\n",
    "        optim.step(grad)\n",
    "        \n",
    "        if loss_running == numpy.Inf:\n",
    "            loss_running = loss\n",
    "        else:\n",
    "            loss_running = 0.95 * loss_running + 0.05 * loss\n",
    "            \n",
    "    n_corrects = 0\n",
    "    n_all = 0\n",
    "    for x, y in val_loader:\n",
    "        x_, y_ = x.data.numpy(), y.data.numpy()\n",
    "        \n",
    "        yp = jnp.argmax(mymodel.forward(x_), -1)\n",
    "        \n",
    "        n_all = n_all + len(y_)\n",
    "        n_corrects = n_corrects + jnp.sum(y_.squeeze() == yp.squeeze())\n",
    "\n",
    "    print(F'epoch {ei+1} loss {loss_running} val acc {n_corrects/n_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(663, dtype=int32), 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_corrects, n_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_.squeeze() == yp.squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 128, 26, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lax.conv(x_, jnp.transpose(mymodel.layers[0].weight,[1,0,2,3]), (1,1), 'VALID').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
