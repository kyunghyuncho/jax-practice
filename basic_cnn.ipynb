{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as jrng\n",
    "from jax import numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Linear, Conv2d, SpatialPool2d, ReLU, Tanh, Softmax\n",
    "from model import Model\n",
    "from optimizers import SGD, Adam\n",
    "from functionals import cross_entropy, weight_decay, clip_norm\n",
    "from utils import flatten_dict, apply_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jrng.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model(rng, [Conv2d(7,7,1,256), ReLU(), \n",
    "                      Conv2d(7,7,256,256), ReLU(), \n",
    "                      Conv2d(7,7,256,256), ReLU(), \n",
    "                      SpatialPool2d(), Linear(256,10), \n",
    "                      Softmax()], \n",
    "                loss=[(cross_entropy, 1.)])\n",
    "# , (weight_decay, 1e-5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(mymodel, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTDataModule('./mnist/')\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.train_dataloader(batch_size=256)\n",
    "val_loader = data.val_dataloader(batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 6.013945579528809 val acc 0.96533203125\n",
      "epoch 2 loss 5.871925354003906 val acc 0.975830078125\n",
      "epoch 3 loss 5.807745456695557 val acc 0.97998046875\n",
      "epoch 4 loss 5.775405406951904 val acc 0.982421875\n",
      "epoch 5 loss 5.750779628753662 val acc 0.985107421875\n",
      "epoch 6 loss 5.734845161437988 val acc 0.98681640625\n",
      "epoch 7 loss 5.726753234863281 val acc 0.98681640625\n",
      "epoch 8 loss 5.723051071166992 val acc 0.988525390625\n",
      "epoch 9 loss 5.707808494567871 val acc 0.989013671875\n",
      "epoch 10 loss 5.698883533477783 val acc 0.99072265625\n",
      "epoch 11 loss 5.690040588378906 val acc 0.991455078125\n",
      "epoch 12 loss 5.683486461639404 val acc 0.99072265625\n",
      "epoch 13 loss 5.685825347900391 val acc 0.99072265625\n",
      "epoch 14 loss 5.673786163330078 val acc 0.9921875\n",
      "epoch 15 loss 5.674094200134277 val acc 0.9921875\n",
      "epoch 16 loss 5.669402599334717 val acc 0.9921875\n",
      "epoch 17 loss 5.670246601104736 val acc 0.992431640625\n",
      "epoch 18 loss 5.66935920715332 val acc 0.992919921875\n",
      "epoch 19 loss 5.658464431762695 val acc 0.99267578125\n",
      "epoch 20 loss 5.6604156494140625 val acc 0.991943359375\n",
      "epoch 21 loss 5.65797233581543 val acc 0.9921875\n",
      "epoch 22 loss 5.649446964263916 val acc 0.9931640625\n",
      "epoch 23 loss 5.648944854736328 val acc 0.993896484375\n",
      "epoch 24 loss 5.651154518127441 val acc 0.99365234375\n",
      "epoch 25 loss 5.644252300262451 val acc 0.993896484375\n",
      "epoch 26 loss 5.638918399810791 val acc 0.993408203125\n",
      "epoch 27 loss 5.640214920043945 val acc 0.994140625\n",
      "epoch 28 loss 5.638512134552002 val acc 0.993896484375\n",
      "epoch 29 loss 5.638123989105225 val acc 0.994140625\n",
      "epoch 30 loss 5.637402057647705 val acc 0.9951171875\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "loss_running = numpy.Inf\n",
    "\n",
    "for ei in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        x_, y_ = x.data.numpy(), y.data.numpy()\n",
    "        loss, grad = mymodel.loss_grad(x_, y_)\n",
    "        grad = clip_norm(grad, thr=1.)\n",
    "        optim.step(grad)\n",
    "        \n",
    "        if loss_running == numpy.Inf:\n",
    "            loss_running = loss\n",
    "        else:\n",
    "            loss_running = 0.95 * loss_running + 0.05 * loss\n",
    "            \n",
    "    n_corrects = 0\n",
    "    n_all = 0\n",
    "    for x, y in val_loader:\n",
    "        x_, y_ = x.data.numpy(), y.data.numpy()\n",
    "        \n",
    "        yp = jnp.argmax(mymodel.forward(x_), -1)\n",
    "        \n",
    "        n_all = n_all + len(y_)\n",
    "        n_corrects = n_corrects + jnp.sum(y_.squeeze() == yp.squeeze())\n",
    "\n",
    "    print(F'epoch {ei+1} loss {loss_running} val acc {n_corrects/n_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = mymodel.params[mymodel.layers[0].name]['weight']\n",
    "# weight = mymodel.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 256\n",
    "w = int(numpy.ceil(numpy.sqrt(fn)))\n",
    "h = int(fn // w)\n",
    "filter_canvas = numpy.zeros((w * (1+weight.shape[-1]), h * (1+weight.shape[-2])))\n",
    "\n",
    "for fid in range(fn):\n",
    "    ri = fid // w\n",
    "    ci = fid % w\n",
    "    filter_canvas[ri * (weight.shape[-1]+1):(ri+1) * (weight.shape[-1]+1)-1,\n",
    "                 ci * (weight.shape[-2]+1):(ci+1) * (weight.shape[-2]+1)-1] = weight[fid][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a28c0760be749b6a4ef89d28c0879ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.figure()\n",
    "\n",
    "plot.imshow(filter_canvas, cmap=cm.gray)\n",
    "\n",
    "plot.axis(False)\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
